from config import META_PATH, NEWS_LIMIT
from fetcher import fetch_nasdaq_news, fetch_article_content
from summarizer import summarize
from embedder import translation
from index_manager import save_index_and_metadata
import numpy as np
import pandas as pd

def run():
    # OpenAI Embeddingì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ì°¨ì› ê°€ì ¸ì˜¤ê¸°
    # embedding = OpenAIEmbeddings()
    # vector_dim = 1536

    # # FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    # db = FAISS(
    #     embedding_function=embedding,
    #     index=faiss.IndexFlatL2(vector_dim),
    #     docstore=InMemoryDocstore(),
    #     index_to_docstore_id={}
    # )

    # ìƒˆë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°í”„ë ˆì„
    df = pd.DataFrame(columns=["id", "title", "date","content","summary"])

    # ê¸°ì‚¬ ìˆ˜ì§‘
    articles = fetch_nasdaq_news(limit=NEWS_LIMIT)
    print(f"ğŸ“° ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")

    # df["date"]ë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜ (ì¤‘ë³µ ì²´í¬ ì •í™•ë„ í–¥ìƒ)
    df["date"] = df["date"].astype(str)

    # ìƒˆ ë¬¸ì„œ ì„ë² ë”© ë° docstore ì„¤ì •
    # new_embeddings = []
    new_rows = []

    # ê¸°ì¡´ title+date ì¡°í•© í‚¤ë¡œ ì¤‘ë³µ ì²´í¬ìš© Set ìƒì„±
    existing_keys = set((df["title"] + "|" + df["date"]).values)

    # ê¸°ì‚¬ ì²˜ë¦¬ ë° ì„ë² ë”© ì¶”ê°€
    for idx, article in enumerate(articles, start=1):
        raw_title = article["title"]
        date_str = article["pub_date"][:10]  # YYYY-MM-DD
        title = f"{raw_title} [{date_str}]"  # ì œëª© + ë‚ ì§œ ì¡°í•©
        url = article["url"]

        # ì¤‘ë³µ ê²€ì‚¬ (title + date ë¬¸ìì—´ ê¸°ì¤€)
        key = f"{title}|{date_str}"
        if key in existing_keys:
            print(f"âš ï¸ ì¤‘ë³µ ê¸°ì‚¬ ìŠ¤í‚µ: {title}")
            continue

        print(f"\n[{idx}] {title}")
        print(f"ğŸ“„ URL: {url}")
        content, _ = fetch_article_content(url)
        if not content:
            print("âŒ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨")
            continue

        summary = summarize(title, content)
        print("ğŸ“ ìš”ì•½ ì™„ë£Œ")

        # # ì„ë² ë”© ìƒì„±
        content = translation(content)
        # new_embeddings.append(vector)
        new_rows.append({
            "id": f"article_{len(df) + len(new_rows) + 1}",
            "title": title,
            "date": date_str,
            "content": content,
            "summary": summary
        })
        # print(content)

    # ìƒˆ ì„ë² ë”© ì¶”ê°€ ë° ì¸ë±ìŠ¤ ì €ì¥
        # ë²¡í„° ì¶”ê°€
        # db.index.add(np.array(new_embeddings))

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)

        # # ë¬¸ì„œ ì €ì¥ì†Œì— ë¬¸ì„œ ì¶”ê°€ ë° ë§¤í•‘
        # for i, row in enumerate(new_rows, start=len(df) - len(new_rows)):
        #     doc_id = f"doc_{i}"
        #     doc_content = row["summary"]
        #     db.docstore.add({doc_id: doc_content})
        #     db.index_to_docstore_id[i] = doc_id

        # ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        # save_index_and_metadata( db.index, db.docstore, db.index_to_docstore_id, df, INDEX_PATH, META_PATH)
    save_index_and_metadata(df, META_PATH)
    print(f"\nâœ… {len(new_rows)}ê°œì˜ ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    run()
